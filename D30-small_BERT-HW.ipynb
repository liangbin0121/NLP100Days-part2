{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"D30-small_BERT-HW.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cd9u5KWer9eR"},"source":["# 作業 : 微調輕量化 Bert 預訓練模型"]},{"cell_type":"markdown","metadata":{"id":"N1BTLCuxr9eS"},"source":["# [作業目標]\n","- 觀察切換 distilBERT 及 Bert 模型帶來的影響\n","- 嘗試並了解前處理對輕量化 Bert 模型帶來的影響"]},{"cell_type":"markdown","metadata":{"id":"YP9uA0WAr9eT"},"source":["# [作業重點]\n","- 試著替換不同的預訓練模型 (DistilBERT / Bert)，觀察有何不同\n","(Hint : 在 In[7] 可以用註解切換不同模型) \n","- 試著註解或跳過\"前處理\"的3個步驟，觀察有何不同"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"memkjblxsEQ-","executionInfo":{"status":"ok","timestamp":1624842076677,"user_tz":-480,"elapsed":424,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"bf7a09e1-0964-4516-e378-7eee0a60e54e"},"source":["# 連接個人資料 讀取 ＰＴＴ 訓練資料和儲存模型\n","#先連接自己的GOOGLE DRIVE 為了要儲存資料和訓練模型\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0pZjw5B3sETt","executionInfo":{"status":"ok","timestamp":1624842076937,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"b702e168-55c6-4e76-b453-7ff9f8de5dd0"},"source":["import os\n","\n","# Current directory\n","print(os.getcwd())\n","\n","# change directory\n","os.chdir('/content/drive/MyDrive/python_training/NLP100Days-part2/D30_small_bert/')\n","print(os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/drive/MyDrive/python_training/NLP100Days-part2/D30_small_bert\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyCzbhBkskSt","executionInfo":{"status":"ok","timestamp":1624842082131,"user_tz":-480,"elapsed":5197,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"59d4d949-1c95-498a-d677-6e265f0de2ed"},"source":["!pip install torch\n","!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FzoFA0idr9eU","executionInfo":{"status":"ok","timestamp":1624842085042,"user_tz":-480,"elapsed":2914,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 載入相關套件, 第一次執行前需安裝 transformers 套件\n","import numpy as np\n","import pandas as pd\n","import torch\n","import transformers as ppb # pytorch transformers\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","import re, warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"kRVzKLKzr9eU","executionInfo":{"status":"ok","timestamp":1624842085045,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 載入訓練與測試資料\n","df = pd.read_csv('data/train.csv')\n","df_test = pd.read_csv('data/test.csv') "],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aEiKhnKJr9eV"},"source":["# 前處理"]},{"cell_type":"code","metadata":{"id":"FyUII-VYr9eV","executionInfo":{"status":"ok","timestamp":1624842085484,"user_tz":-480,"elapsed":444,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 前處理-1 : 消除連字\n","def decontracted(text):\n","    # 特殊連字\n","    text = re.sub(r\"(W|w)on(\\'|\\’)t \", \"will not \", text)\n","    text = re.sub(r\"(C|c)an(\\'|\\’)t \", \"can not \", text)\n","    text = re.sub(r\"(Y|y)(\\'|\\’)all \", \"you all \", text)\n","    text = re.sub(r\"(Y|y)a(\\'|\\’)ll \", \"you all \", text)\n","    # 一般性連字\n","    text = re.sub(r\"(I|i)(\\'|\\’)m \", \"i am \", text)\n","    text = re.sub(r\"(A|a)in(\\'|\\’)t \", \"is not \", text)\n","    text = re.sub(r\"n(\\'|\\’)t \", \" not \", text)\n","    text = re.sub(r\"(\\'|\\’)re \", \" are \", text)\n","    text = re.sub(r\"(\\'|\\’)s \", \" is \", text)\n","    text = re.sub(r\"(\\'|\\’)d \", \" would \", text)\n","    text = re.sub(r\"(\\'|\\’)ll \", \" will \", text)\n","    text = re.sub(r\"(\\'|\\’)t \", \" not \", text)\n","    text = re.sub(r\"(\\'|\\’)ve \", \" have \", text)\n","    return text\n","\n","df['text'] = df['text'].apply(lambda x: decontracted(x))\n","df_test['text'] = df_test['text'].apply(lambda x: decontracted(x))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"A3_s6WBEr9eW","executionInfo":{"status":"ok","timestamp":1624842085485,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 前處理-2 : 清除特殊符號\n","import string\n","regular_punct = list(string.punctuation)\n","extra_punct = [\n","    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n","    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n","    '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n","    '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n","    '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n","    '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n","    '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n","    'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n","    '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n","    '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n","# 消除標點符號以及上列符號\n","all_punct = list(set(regular_punct + extra_punct))\n","# 消除連字號 \"-\" 以及句號 \".\"\n","all_punct.remove('-')\n","all_punct.remove('.')\n","\n","def spacing_punctuation(text):\n","    \"\"\"\n","    add space before and after punctuation and symbols\n","    \"\"\"\n","    for punc in all_punct:\n","        if punc in text:\n","            text = text.replace(punc, f' {punc} ')\n","    return text\n","\n","df['text'] = df['text'].apply(lambda x: spacing_punctuation(x))\n","df_test['text'] = df_test['text'].apply(lambda x: spacing_punctuation(x))"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_NLnqwd3o7o","executionInfo":{"status":"ok","timestamp":1624842085757,"user_tz":-480,"elapsed":274,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 前處理-3 : 錯漏字修正\n","mis_connect_list = ['(W|w)hat', '(W|w)hy', '(H|h)ow', '(W|w)hich', '(W|w)here', '(W|w)ill']\n","mis_connect_re = re.compile('(%s)' % '|'.join(mis_connect_list))\n","\n","mis_spell_mapping = {'whattsup': 'WhatsApp', 'whatasapp':'WhatsApp', 'whatsupp':'WhatsApp', \n","                      'whatcus':'what cause', 'arewhatsapp': 'are WhatsApp', 'Hwhat':'what',\n","                      'Whwhat': 'What', 'whatshapp':'WhatsApp', 'howhat':'how that',\n","                      # why\n","                      'Whybis':'Why is', 'laowhy86':'Foreigners who do not respect China',\n","                      'Whyco-education':'Why co-education',\n","                      # How\n","                      \"Howddo\":\"How do\", 'Howeber':'However', 'Showh':'Show',\n","                      \"Willowmagic\":'Willow magic', 'WillsEye':'Will Eye', 'Williby':'will by'}\n","def spacing_some_connect_words(text):\n","    \"\"\"\n","    'Whyare' -> 'Why are'\n","    \"\"\"\n","    ori = text\n","    for error in mis_spell_mapping:\n","        if error in text:\n","            text = text.replace(error, mis_spell_mapping[error])\n","            \n","    # what\n","    text = re.sub(r\" (W|w)hat+(s)*[A|a]*(p)+ \", \" WhatsApp \", text)\n","    text = re.sub(r\" (W|w)hat\\S \", \" What \", text)\n","    text = re.sub(r\" \\S(W|w)hat \", \" What \", text)\n","    # why\n","    text = re.sub(r\" (W|w)hy\\S \", \" Why \", text)\n","    text = re.sub(r\" \\S(W|w)hy \", \" Why \", text)\n","    # How\n","    text = re.sub(r\" (H|h)ow\\S \", \" How \", text)\n","    text = re.sub(r\" \\S(H|h)ow \", \" How \", text)\n","    # which\n","    text = re.sub(r\" (W|w)hich\\S \", \" Which \", text)\n","    text = re.sub(r\" \\S(W|w)hich \", \" Which \", text)\n","    # where\n","    text = re.sub(r\" (W|w)here\\S \", \" Where \", text)\n","    text = re.sub(r\" \\S(W|w)here \", \" Where \", text)\n","    \n","    text = mis_connect_re.sub(r\" \\1 \", text)\n","    text = text.replace(\"What sApp\", 'WhatsApp') \n","    return text\n","\n","df['text'] = df['text'].apply(lambda x: spacing_some_connect_words(x))\n","df_test['text'] = df_test['text'].apply(lambda x: spacing_some_connect_words(x))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"CV3qCOFgr9eX","executionInfo":{"status":"ok","timestamp":1624842085758,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"6e32246d-85dc-493a-b17f-645536b3549f"},"source":["df.head() "],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this  # earthquake...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to  ' shelter in place '  ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13 , 000 people receive  # wildfires evacuatio...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby  # Alaska a...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id keyword  ...                                               text target\n","0   1     NaN  ...  Our Deeds are the Reason of this  # earthquake...      1\n","1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n","2   5     NaN  ...  All residents asked to  ' shelter in place '  ...      1\n","3   6     NaN  ...  13 , 000 people receive  # wildfires evacuatio...      1\n","4   7     NaN  ...  Just got sent this photo from Ruby  # Alaska a...      1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"_-xJpfkCr9eY"},"source":["# 載入 distilBERT 模型或 Bert 模型, 將文字編碼"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1v45cO4tr9eZ","executionInfo":{"status":"ok","timestamp":1624842101461,"user_tz":-480,"elapsed":15706,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"491df21d-c326-4758-d55e-978eb9c9ebe1"},"source":["# 載入 distilBERT 模型或 Bert 模型 (下列兩行中, 將不選的模型註解掉即可)\n","#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n","model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n","\n","# 載入預訓練權重以及 tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ecoO1CpIr9eZ","executionInfo":{"status":"ok","timestamp":1624842101462,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 調整訓練資料的大小 (可取消, 若不取消表示取前4000筆訓練)\n","df = df[:4000]"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AYT_Aerpr9eZ"},"source":["# 將訓練資料經由 distilBERT 或 Bert 轉換為 Embedding 編碼"]},{"cell_type":"code","metadata":{"id":"cHGFeM19r9ea","executionInfo":{"status":"ok","timestamp":1624842103771,"user_tz":-480,"elapsed":2319,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 將訓練資料經過 tokenizer 編碼轉換\n","tokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gdw1kKTrr9ea","executionInfo":{"status":"ok","timestamp":1624842103772,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 以最長字串為準, 將訓練資料補零成相同長度\n","max_len = 0\n","for i in tokenized.values:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","\n","padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvwVrw9Fr9ea","executionInfo":{"status":"ok","timestamp":1624842750491,"user_tz":-480,"elapsed":646721,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 設定 attention_mask, 將計算經過 Bert 生成的 Embedding 結果, 儲存於 last_hidden_states 中\n","attention_mask = np.where(padded != 0, 1, 0)\n","input_ids = torch.tensor(padded).to(torch.int64)\n","attention_mask = torch.tensor(attention_mask).to(torch.int64)\n","\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AkldU564r9ea","executionInfo":{"status":"ok","timestamp":1624842750493,"user_tz":-480,"elapsed":15,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"e8d7252d-9843-43d2-c96e-1df73f3b09a6"},"source":["# 準備下一階段要用的特徵 (上階段 Embedding 結果) 與目標值\n","labels = df['target']\n","features = last_hidden_states[0][:,0,:].numpy()\n","features[0].shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(768,)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"FyIijGgO3JAf"},"source":["DistiBERT with preprocess: 768\n","\n","DistiBERT without preprocess: 768\n","\n","BERT without preprocess: 768\n","\n","BERT with preprocess: 768"]},{"cell_type":"code","metadata":{"id":"cGA0RlUbr9ea","executionInfo":{"status":"ok","timestamp":1624842750493,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 切割訓練 / 測試集\n","train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsaxCbRsr9ea"},"source":["# 使用 Logistic Regression 當作最後一層, 輸出預測結果"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PEIsFzaJr9eb","executionInfo":{"status":"ok","timestamp":1624842775039,"user_tz":-480,"elapsed":24557,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"2ddf0ebe-72a7-4618-c371-8db5e86e69d1"},"source":["# 對 Logistic Regression 跑參, 相當於加上單層類神經網路\n","import sklearn\n","from sklearn.model_selection import GridSearchCV\n","parameters = {'C': np.linspace(0.0001, 100, 20)}\n","grid_search = GridSearchCV(LogisticRegression(), parameters)\n","grid_search.fit(train_features, train_labels)\n","print('best parameters: ', grid_search.best_params_)\n","print('best scrores: ', grid_search.best_score_)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["best parameters:  {'C': 5.263252631578947}\n","best scrores:  0.766\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OK6-NWJu3Cw_"},"source":["DistiBERT with preprocess:\n","\n","best parameters:  {'C': 5.263252631578947}\n","\n","best scrores:  0.783\n","\n","DistiBERT without preprocess:\n","\n","best parameters:  {'C': 5.263252631578947}\n","\n","best scrores:  0.7939999999999999\n","\n","BERT without preprocess:\n","\n","best parameters:  {'C': 5.263252631578947}\n","\n","best scrores:  0.768\n","\n","BERT with preprocess:\n","\n","best parameters:  {'C': 5.263252631578947}\n","\n","best scrores:  0.766"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9h6Bhn2Ur9eb","executionInfo":{"status":"ok","timestamp":1624842775455,"user_tz":-480,"elapsed":426,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"c48b0211-8b48-41fc-836b-dbbf6f5e1267"},"source":["# 將上一格跑出的 Logistic Regression 最佳 C 值填入, 觀察測試集的驗證分數\n","lr_clf = LogisticRegression(C = 5.263252631578947)  \n","lr_clf.fit(train_features, train_labels)\n","lr_clf.score(test_features, test_labels)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.779"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"9eZU0vMy3ATX"},"source":["DistiBERT with preprocess: 0.807\n","\n","DistiBERT without preprocess: 0.808\n","\n","BERT without preprocess: 0.792\n","\n","BERT with preprocess: 0.779"]},{"cell_type":"markdown","metadata":{"id":"tNEBN8Ynr9eb"},"source":["# 對預測目標資料做出最終預測"]},{"cell_type":"code","metadata":{"id":"t6iIIUirr9eb","executionInfo":{"status":"ok","timestamp":1624842777545,"user_tz":-480,"elapsed":2092,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 將預測目標資料經過 tokenizer 編碼轉換\n","tokenized_t = df_test['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjdRujFnr9ec","executionInfo":{"status":"ok","timestamp":1624842777547,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"667cc1b7-4031-445c-8d0c-8a20c1bc1ea0"},"source":["# 以最長字串為準, 將預測目標資料補零成相同長度\n","max_len = 0\n","for i in tokenized_t.values:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","        \n","padded_t = np.array([i + [0]*(max_len-len(i)) for i in tokenized_t.values])\n","np.array(padded_t).shape"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3263, 73)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"2yZ0ApcJ28n6"},"source":["DistiBERT with preprocess: (3263, 73)\n","\n","DistiBERT without preprocess: (3263, 73)\n","\n","BERT without preprocess: (3263, 73)\n","\n","BERT with preprocess: (3263, 73)"]},{"cell_type":"code","metadata":{"id":"g2Qxx5Vfr9ec","executionInfo":{"status":"ok","timestamp":1624843177295,"user_tz":-480,"elapsed":399751,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 設定 attention_mask, 將計算經過 Bert 生成的 Embedding 結果, 儲存於 last_hidden_states 中\n","attention_mask_t = np.where(padded_t != 0, 1, 0)\n","input_ids = torch.tensor(padded_t).to(torch.int64)\n","attention_mask_t = torch.tensor(attention_mask_t).to(torch.int64)\n","\n","with torch.no_grad():\n","    last_hidden_states = model(input_ids, attention_mask=attention_mask_t)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mctDJLoUr9ec","executionInfo":{"status":"ok","timestamp":1624843177295,"user_tz":-480,"elapsed":13,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"4095ee4e-4d3c-4450-f8ae-0990f853aba8"},"source":["# 輸出預測目標資料的預測結果\n","val_features = last_hidden_states[0][:,0,:].numpy() \n","y_pred = lr_clf.predict(val_features)\n","y_pred"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, ..., 1, 0, 1])"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"zngFasqH2zi7"},"source":["DistiBERT with preprocess:\n","\n","array([1, 1, 1, ..., 1, 1, 0])\n","\n","DistiBERT without preprocess:\n","\n","array([1, 1, 1, ..., 1, 1, 0])\n","\n","BERT without preprocess:\n","\n","array([1, 1, 1, ..., 1, 0, 1])\n","\n","\n","BERT with preprocess:\n","\n","array([1, 1, 1, ..., 1, 0, 1])"]},{"cell_type":"code","metadata":{"id":"00brLMcir9ec","executionInfo":{"status":"ok","timestamp":1624843177295,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 生成提交擋\n","submission = pd.DataFrame()\n","submission['id'] = df_test['id']\n","submission['target'] = y_pred\n","#submission.to_csv('submission_DistilBert_wpreprocess.csv', index=False)\n","#submission.to_csv('submission_DistilBert_wopreprocess.csv', index=False)\n","#submission.to_csv('submission_Bert_wopreprocess.csv', index=False)\n","submission.to_csv('submission_Bert_wpreprocess.csv', index=False)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Ld6PYryr9ec","executionInfo":{"status":"ok","timestamp":1624843177297,"user_tz":-480,"elapsed":13,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":[""],"execution_count":23,"outputs":[]}]}