{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project_1_1_lstm_writer_hw.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rSmJJczZo5zp"},"source":["# 專題（一）：訓練LSTM之歌詞自動填詞器\n","\n","## 專案目標\n","- 目標：使用 LSTM 模型去學習五月天歌詞，並且可以自動填詞來產生歌詞\n","- mayday_lyrics.txt 資料說明：\n","    - 每一行都是一首歌的歌詞\n","    - 除去標點符號並以空白表示間格\n","- 利用 mayday_lyrics.txt 來產生歌詞的序列\n","- 使用 LSTM 模型去學習歌詞的序列\n","- 當我們給定開頭的一段歌詞，例如：”給我一首歌”，就可以用 LSTM 猜下一個字，反覆這個過程就可以自動填詞\n","\n","## 實作提示\n","- STEP1：從 mayday_lyrics.txt 中取出歌詞\n","- STEP2：建立每個字的 Index\n","- STEP3：用 Rolling 的方式打造 LyricsDataset\n","- STEP4：使用 DataLoader 來包裝 LyricsDataset\n","- STEP5：建立 LSTM 模型： inputs > nn.Embedding > nn.LSTM > nn.Dropout > 取最後一個 state > nn.Linear > softmax\n","- STEP6：開始訓練並調整參數\n","- STEP7：進行 Demo，給定 pre_text ，使用模型迭代的預測下一個字產生歌詞\n","- (進階) STEP8：在 Demo 時可以採用依照 Softmax 機率來作隨機採樣，這可以增加隨機性，讓歌詞有更多變化，當然你還可以使用機率閥值來避免太奇怪的字出現\n","\n","## 重要知識點：專題結束後你可以學會\n","- 如何讀取並處理需要 Rolling 的序列資料\n","- 了解如何用 Pytorch 建制一個 LSTM 的模型\n","- 學會如何訓練一個語言模型\n","- 學會如何隨機抽樣自 Softmax 的分布"]},{"cell_type":"code","metadata":{"id":"0EW8afmyQ-oD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537344443,"user_tz":-480,"elapsed":336,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"5bd35325-5556-4c95-8e29-45bbb97d1fcd"},"source":["# 連接個人資料 讀取 ＰＴＴ 訓練資料和儲存模型\n","#先連接自己的GOOGLE DRIVE 為了要儲存資料和訓練模型\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tZDa1RCyQ-qp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537345117,"user_tz":-480,"elapsed":403,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"e48a9301-3a7e-4e4a-92cb-f0b1e27a286b"},"source":["import os\n","\n","# Current directory\n","print(os.getcwd())\n","\n","# change directory\n","os.chdir('/content/drive/MyDrive/python_training/NLP100Days-part2/project_1_1/')\n","print(os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/drive/MyDrive/python_training/NLP100Days-part2/project_1_1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mo4f-ouXRB_5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537349946,"user_tz":-480,"elapsed":4832,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"0f96dce8-413f-4c39-d01e-8b2621aaa110"},"source":["!pip install torch\n","#!pip install transformers\n","# 設定 torchtext 版本 安裝完必須重新啟動執行階段\n","!pip install torchtext==0.6.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.9.0+cu102)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.5.30)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hen1MQ1F_cly","executionInfo":{"status":"ok","timestamp":1626537350409,"user_tz":-480,"elapsed":466,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import random_split\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm.notebook import tqdm\n","from collections import Counter"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"4RLB3Z6K62Xv","executionInfo":{"status":"ok","timestamp":1626537350410,"user_tz":-480,"elapsed":14,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# from: https://github.com/gaussic/Chinese-Lyric-Corpus\n","with open('mayday_lyrics.txt', encoding='utf-8') as f:\n","    lyrics_list = [line.strip() for line in f.readlines()]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EU9zOCWJ4QH9","executionInfo":{"status":"ok","timestamp":1626537350410,"user_tz":-480,"elapsed":13,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"f021a311-5f2f-44b2-cefb-37ee8dccf52b"},"source":["lyrics_list[:5]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['摸不到的顏色 是否叫彩虹 看不到的擁抱 是否叫做微風 一個人 想著一個人 是否就叫寂寞 命運偷走如果 只留下結果 時間偷走初衷 只留下了苦衷 你來過 然後你走後 只留下星空 那一年我們望著星空 有那麼多的燦爛的夢 以為快樂會永久 像不變星空 陪著我 獵戶 天狼 織女光年外沈默 回憶 青春 夢想何時偷偷隕落 我愛過 然後我沈默 人海裡漂流 那一年我們望著星空 未來的未來從沒想過 當故事失去美夢 美夢失去線索 而我們失去聯絡 這一片無言無語星空 為什麼靜靜看我淚流 如果你在的時候 會不會伸手 擁抱我 細數繁星閃爍 細數此生奔波 原來所有 所得 所獲 不如一夜的星空 空氣中的溫柔 回憶你的笑容 徬佛只要伸手 就能觸摸 摸不到的顏色 是否叫彩虹 看不到的擁抱 是否叫做微風 一個人 習慣一個人 這一刻獨自望著星空 從前的從前從沒變過 寂寞可以是忍受 也可以是享受 享受僅有的擁有 那一年我們望著星空 有那麼多的燦爛的夢 至少回憶會永久 像不變星空 陪著我 最後只剩下星空 像不變回憶 陪著我',\n"," '如果你眼神能夠為我 片刻的降臨 如果你能聽到 心碎的聲音 沈默的守護著你 沈默的等奇跡 沈默的讓自己 像是空氣 大家都吃著聊著笑著 今晚多開心 最角落里的我 笑得多合群 盤底的洋蔥像我 永遠是調味品 偷偷地看著你 偷偷地隱藏著自己 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意 聽你說你和你的他們 曖昧的空氣 我和我的絕望 裝得很風趣 我就像一顆洋蔥 永遠是配角戲 多希望能與你 有一秒專屬的劇情 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意 如果你願意一層一層一層的剝開我的心 你會發現你會訝異 你是我最壓抑最深處的秘密 如果你願意一層一層一層的剝開我的心 你會鼻酸你會流淚 只要你能看到我聽到我的全心全意 你會鼻酸你會流淚 只要你能聽到我看到我的全心全意',\n"," '人群中哭著 你只想變成透明的顏色 你再也不會夢或痛或心動了 你已經決定了 你已經決定了 你靜靜忍著 緊緊把昨天在拳心握著 而回憶越是甜就是越傷人 越是在手心留下 密密麻麻深深淺淺的刀割 你不是真正的快樂 你的笑只是你穿的保護色 你決定不恨了 也決定不愛了 把你的靈魂關在 永遠鎖上的軀殼 這世界笑了 於是你合群的一起笑了 當生存是規則 不是你的選擇 於是你含著眼淚 飄飄蕩蕩跌跌撞撞地走著 你不是真正的快樂 你的笑只是你穿的保護色 你決定不恨了 也決定不愛了 把你的靈魂關在 永遠鎖上的軀殼 你不是真正的快樂 你的傷從不肯完全的愈合 我站在你左側 卻像隔著銀河 難道就真的抱著 遺憾一直到老了 然後再後悔著 你不是真正的快樂 你的笑只是你穿的保護色 你決定不恨了 也決定不愛了 把你的靈魂關在 永遠鎖上的軀殼 你不是真正的快樂 你的傷從不肯完全的愈合 我站在你左側 卻像隔著銀河 難道就真的抱著 遺憾一直到老了 你值得真正的快樂 你應該脫下你穿的保護色 為什麼失去了 還要被懲罰呢 能不能就讓悲傷 全部結束在此刻 重新開始活著',\n"," '當煙霧隨晨光飄散 枕畔的湖已風乾 期待已退化成等待 而我告別了突然 當淚痕勾勒成遺憾 回憶誇飾著傷感 逝水比喻時光荏苒 終於我們不再 為了生命狂歡 為愛情狂亂 然而青春彼岸 盛夏正要一天 一天一天的燦爛 誰說不能讓我 此生唯一自傳 如同詩一般 無論多遠未來 讀來依然一字一句 一篇都燦爛 讓天空解釋著蔚藍 浮雲定義著潔白 落花鋪陳一片紅色地毯 迎接我們到未來 精彩未完的未來',\n"," '你用哭聲打卡 產房裡的娃娃 眾人祝福 你還記得嗎 當時一絲不掛 如今一分不差 成天會議 成堆資料夾 第一個部門 主管叫做爸媽 你只要乖乖聽話 第二個部門 專門改造傻瓜 會念書 會考試的那種傻瓜 你曾掙扎過嗎 你曾反抗過嗎 如何使用生命 就叫使命是嗎 人生有限選擇 誰在規劃 追逐富貴榮華 目標飛黃騰達 你準備好了嗎 現在必須出發 人在哪裡跌倒 就在哪趴一下 面對挫折也都專業化 讓生涯最佳化 而夢想最小化 生存機率追求最大化 第三個部門 負責財務計劃 要你和現實打架 第四個部門 任務更加複雜 去尋覓 去戀愛去找她或他 你曾深愛過嗎 你曾放縱過嗎 愛成一句傻話 活成一句廢話 人生有限日子揮霍一下 公司漸漸變化 組織慢慢擴大 有時無法招架 有點騎虎難下 人生有限公司 還加班還沒回家 你曾停下過嗎 你曾懷疑過嗎 就算你有想法 你也沒有辦法 人生無限問題沒有解答 追逐富貴榮華 目標飛黃騰達 其實平安到達 就是一種偉大 人生無限可能 誰能出價 人生像打電話 總要有人先掛 來時嗚嗚哇哇 走要嘻嘻哈哈 人生有限的話 你想要怎樣喧嘩']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"hzhYeIIn74ZK","executionInfo":{"status":"ok","timestamp":1626537350410,"user_tz":-480,"elapsed":10,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 建立詞典對照表\n","from collections import Counter\n","cnt = Counter(''.join(lyrics_list))\n","word2index = {word: idx for idx, word in enumerate(cnt)}\n","index2word = {idx: word for word, idx in word2index.items()}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"guUN6POF9NpH","executionInfo":{"status":"ok","timestamp":1626537350411,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"d58dc4d9-f805-49b2-db3b-13c4cb11659d"},"source":["cnt[' ']"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8587"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLXlIZMO-HOj","executionInfo":{"status":"ok","timestamp":1626537350411,"user_tz":-480,"elapsed":8,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"d600444c-f61f-498f-88e4-5f000d4ef352"},"source":["cnt['摸']"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"nueOEx287Hpm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537350411,"user_tz":-480,"elapsed":7,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"c6b186f7-812c-4eff-ee7f-82d00349086b"},"source":["vocab_siz=len(word2index)\n","vocab_siz\n"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2101"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"y40ZwRz6R1p9","executionInfo":{"status":"ok","timestamp":1626537350412,"user_tz":-480,"elapsed":7,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 建立數據集\n","class LyricsDataset(Dataset):\n","    def __init__(self, lyrics_list, word2index, num_unrollings=10):\n","      ## Code Here\n","        self.word2index = word2index\n","        self.samples = []\n","        for lyrics in lyrics_list:\n","            for idx in range(len(lyrics) - num_unrollings + 1):##重覆取num_unrollings為一組數據\n","                self.samples.append(lyrics[idx:idx + num_unrollings])\n","\n","    def __getitem__(self, idx):\n","      ## Code Here\n","        sample = self.samples[idx]\n","        #取前num_unrollings-1為training data\n","        input_lyric = torch.LongTensor([self.word2index[w] for w in sample[:-1]])\n","        #取最後一字為label\n","        output_lyric = torch.LongTensor([self.word2index[sample[-1]]])\n","\n","        return input_lyric, output_lyric\n","\n","    def __len__(self):\n","        return len(self.samples)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"_L7UokS6_W7O","executionInfo":{"status":"ok","timestamp":1626537350413,"user_tz":-480,"elapsed":8,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["batch_size = 128\n","\n","dataset = LyricsDataset(lyrics_list, word2index)\n","\n","train_loader = DataLoader(\n","    dataset=dataset,\n","    batch_size=batch_size,\n","    shuffle=True)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYsaS93sR1vt","executionInfo":{"status":"ok","timestamp":1626537350413,"user_tz":-480,"elapsed":7,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["class LSTM_LM(nn.Module):\n","    def __init__(self, vocab_size, n_hidden, num_layers, dropout_ratio):\n","        super(LSTM_LM, self).__init__()\n","        # Code Here\n","        self.embedded = nn.Embedding(vocab_size, n_hidden)\n","        self.lstm = nn.LSTM(input_size=n_hidden,\n","                            hidden_size=n_hidden,\n","                            num_layers=num_layers,\n","                            batch_first=True,\n","                            dropout=dropout_ratio)\n","        self.fc = nn.Linear(n_hidden, vocab_size)\n","        self.dropout = nn.Dropout(dropout_ratio)\n","\n","    def forward(self, inputs):\n","      ## Code Here\n","        embedded = self.embedded(inputs)  # [batch_size, num_unrollings - 1, n_hidden]\n","        outputs, _ = self.lstm(embedded)\n","        outputs = self.dropout(outputs)\n","        outputs = outputs[:,-1]  # [batch_size, n_hidden]\n","        logits = self.fc(outputs)# [batch_size, vocab_size]\n","\n","        return logits"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"2VvKkT_J6r4B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537350678,"user_tz":-480,"elapsed":7,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"7e58eebc-405b-47fc-ea9e-735e6d41cea1"},"source":["# 載入 pytorch 套件, 依照現有環境判定是否使用 GPU 計算\n","if torch.cuda.is_available():       \n","    device = torch.device(\"cuda\")\n","    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n","    print('Device name:', torch.cuda.get_device_name(0))\n","\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","Device name: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FLL3vOpyR1yl","executionInfo":{"status":"ok","timestamp":1626537350679,"user_tz":-480,"elapsed":4,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def train_batch(model, data, criterion, optimizer, device):##\n","    model.train()\n","    inputs, targets = [d.to(device) for d in data]\n","    outputs = model(inputs)\n","    loss = criterion(outputs, targets.view(-1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    return loss.item()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_QVIJqHRsnX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537549346,"user_tz":-480,"elapsed":198671,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"7f1b7ba6-a6f4-4f6b-ebf4-c47b60eb42f7"},"source":["# 訓練模型\n","epochs = 100\n","lr = 0.001\n","\n","model = LSTM_LM(vocab_siz,128, 2, 0.2) ##128, len(word2index), 2, 0.2\n","\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss(size_average=False)\n","#criterion.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","\n","for epoch in range(1, 1 + epochs):\n","    tot_train_loss = 0\n","    tot_train_count = 0\n","\n","    for train_data in train_loader:\n","        loss = train_batch(model, train_data, criterion, optimizer, device)\n","\n","        tot_train_loss += loss\n","        tot_train_count += train_data[0].size(0)\n","\n","    print('epoch ', epoch, 'train_loss: ', tot_train_loss / tot_train_count)\n","\n","    if epoch % 10 == 0:\n","        for idx in [0, 50, 99]:\n","            input_batch = dataset[idx][0].unsqueeze(0).to(device)\n","            predict = model(input_batch).argmax(dim=-1).item()\n","            print('Example: \"{}\"+\"{}\"'.format(dataset.samples[idx][:-1], index2word[predict]))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"stream","text":["epoch  1 train_loss:  5.6476752105846755\n","epoch  2 train_loss:  5.210829824514929\n","epoch  3 train_loss:  4.881647736190876\n","epoch  4 train_loss:  4.613010041510349\n","epoch  5 train_loss:  4.377096993544495\n","epoch  6 train_loss:  4.160727202978758\n","epoch  7 train_loss:  3.9573896324851416\n","epoch  8 train_loss:  3.762858517385818\n","epoch  9 train_loss:  3.5894943487493576\n","epoch  10 train_loss:  3.4255059252598077\n","Example: \"摸不到的顏色 是否\"+\"不\"\n","Example: \" 只留下結果 時間\"+\"一\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  11 train_loss:  3.2595346208916407\n","epoch  12 train_loss:  3.1206116621749658\n","epoch  13 train_loss:  2.978181263248158\n","epoch  14 train_loss:  2.8473125902610583\n","epoch  15 train_loss:  2.7252000885012433\n","epoch  16 train_loss:  2.6203404478189083\n","epoch  17 train_loss:  2.5131222139423883\n","epoch  18 train_loss:  2.4214995497727934\n","epoch  19 train_loss:  2.3179937237709782\n","epoch  20 train_loss:  2.231065293742337\n","Example: \"摸不到的顏色 是否\"+\"就\"\n","Example: \" 只留下結果 時間\"+\"之\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  21 train_loss:  2.149156388709307\n","epoch  22 train_loss:  2.0718438132982557\n","epoch  23 train_loss:  1.9966223207941767\n","epoch  24 train_loss:  1.9294538048944743\n","epoch  25 train_loss:  1.8615276027750307\n","epoch  26 train_loss:  1.8034910093997831\n","epoch  27 train_loss:  1.751116679261103\n","epoch  28 train_loss:  1.7015039804728707\n","epoch  29 train_loss:  1.644960883704389\n","epoch  30 train_loss:  1.6014790784545394\n","Example: \"摸不到的顏色 是否\"+\"放\"\n","Example: \" 只留下結果 時間\"+\"有\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  31 train_loss:  1.5483273436050997\n","epoch  32 train_loss:  1.5099503244146335\n","epoch  33 train_loss:  1.467043892097263\n","epoch  34 train_loss:  1.4315544250279224\n","epoch  35 train_loss:  1.391100445803323\n","epoch  36 train_loss:  1.3544136447212192\n","epoch  37 train_loss:  1.3211969229916822\n","epoch  38 train_loss:  1.287090969250686\n","epoch  39 train_loss:  1.2640247913612117\n","epoch  40 train_loss:  1.2294148150025832\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"都\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  41 train_loss:  1.1976381469572437\n","epoch  42 train_loss:  1.1759817834114858\n","epoch  43 train_loss:  1.1525728809832068\n","epoch  44 train_loss:  1.1283320354077486\n","epoch  45 train_loss:  1.1062176055285564\n","epoch  46 train_loss:  1.082864561611409\n","epoch  47 train_loss:  1.0533934305330135\n","epoch  48 train_loss:  1.0359047216622697\n","epoch  49 train_loss:  1.0213847720731137\n","epoch  50 train_loss:  0.9999175462115638\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"卻\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  51 train_loss:  0.9876701559038074\n","epoch  52 train_loss:  0.9720340560175585\n","epoch  53 train_loss:  0.9424741842090806\n","epoch  54 train_loss:  0.9331338728053146\n","epoch  55 train_loss:  0.9082958098247267\n","epoch  56 train_loss:  0.9093712474474747\n","epoch  57 train_loss:  0.8887871843960685\n","epoch  58 train_loss:  0.8777945845329138\n","epoch  59 train_loss:  0.8617614354077825\n","epoch  60 train_loss:  0.8412959686273164\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"偷\"\n","Example: \"麼多的燦爛的夢 以\"+\"擱\"\n","epoch  61 train_loss:  0.8290476424361201\n","epoch  62 train_loss:  0.8276657640101736\n","epoch  63 train_loss:  0.808218663498308\n","epoch  64 train_loss:  0.7993666982083282\n","epoch  65 train_loss:  0.7822987875760007\n","epoch  66 train_loss:  0.7753597628746755\n","epoch  67 train_loss:  0.7711487046812685\n","epoch  68 train_loss:  0.7530833236107428\n","epoch  69 train_loss:  0.7482106057957968\n","epoch  70 train_loss:  0.7327213195024282\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"卻\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  71 train_loss:  0.7291694526860022\n","epoch  72 train_loss:  0.7196080576874985\n","epoch  73 train_loss:  0.7082490061392015\n","epoch  74 train_loss:  0.7030971982637714\n","epoch  75 train_loss:  0.6939337138950646\n","epoch  76 train_loss:  0.6928734004642313\n","epoch  77 train_loss:  0.6810920163956516\n","epoch  78 train_loss:  0.6711134937498967\n","epoch  79 train_loss:  0.6633007760512308\n","epoch  80 train_loss:  0.656934343810025\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"偷\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  81 train_loss:  0.6519235301858974\n","epoch  82 train_loss:  0.6406279256138309\n","epoch  83 train_loss:  0.6393328613806026\n","epoch  84 train_loss:  0.6379001006558768\n","epoch  85 train_loss:  0.633790580765911\n","epoch  86 train_loss:  0.6218922334413732\n","epoch  87 train_loss:  0.6193748817680838\n","epoch  88 train_loss:  0.6068948596200846\n","epoch  89 train_loss:  0.6075534299496447\n","epoch  90 train_loss:  0.6062389320148345\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"偷\"\n","Example: \"麼多的燦爛的夢 以\"+\"為\"\n","epoch  91 train_loss:  0.5941773133574296\n","epoch  92 train_loss:  0.5866286667237034\n","epoch  93 train_loss:  0.5872950164374883\n","epoch  94 train_loss:  0.5801419154172291\n","epoch  95 train_loss:  0.5768769872877496\n","epoch  96 train_loss:  0.5625495582075789\n","epoch  97 train_loss:  0.568790529506906\n","epoch  98 train_loss:  0.5574202552035977\n","epoch  99 train_loss:  0.5623154219508102\n","epoch  100 train_loss:  0.5531777336719812\n","Example: \"摸不到的顏色 是否\"+\"叫\"\n","Example: \" 只留下結果 時間\"+\"偷\"\n","Example: \"麼多的燦爛的夢 以\"+\"一\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NDNVBZt-R14l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537549346,"user_tz":-480,"elapsed":25,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"6a0d8821-933a-4988-bd0f-dfe18a478cae"},"source":["# 模型inference\n","pre_text = '給我一首歌'\n","generate_len = 50\n","prob_threshold = 0.01\n","\n","result = [word2index[c] for c in pre_text]\n","for _ in range(generate_len):\n","    input_example = torch.LongTensor([result]).to(device)\n","    logit = model(input_example)\n","    ## Code Here\n","    prob = F.softmax(logit, dim=-1)\n","    probs = torch.where(prob > prob_threshold, prob, torch.zeros_like(prob))\n","    predict = torch.multinomial(probs, 1).item()\n","    ## End\n","    result += [predict]\n","\n","print(''.join([index2word[i] for i in result]))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["給我一首歌 為衝淡了名代定降落 我心臟 能忘你 明天真正講不是不知道 這到夏天全整個故事 盛起 親像了雪如而采\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5BEqCfcDIhTS","executionInfo":{"status":"ok","timestamp":1626537549347,"user_tz":-480,"elapsed":16,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"c0bb6c1c-d281-4b3b-e657-efd5dc1654e3"},"source":["logit"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-18.0657, -10.5613, -17.3867,  ..., -19.5275, -30.4466, -13.6933]],\n","       device='cuda:0', grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"BCa3lBrASQds","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626537549347,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"df9f2083-df38-48a5-be44-fa2a171f5eef"},"source":["prob"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[6.5773e-10, 1.1944e-06, 1.2969e-09,  ..., 1.5246e-10, 2.7610e-15,\n","         5.2112e-08]], device='cuda:0', grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsplU8J4LYc_","executionInfo":{"status":"ok","timestamp":1626537549348,"user_tz":-480,"elapsed":11,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"f45eee4e-1864-4cba-87d7-919b6176426d"},"source":["probs"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n","       grad_fn=<SWhereBackward>)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sfKvME16LdO3","executionInfo":{"status":"ok","timestamp":1626537549348,"user_tz":-480,"elapsed":9,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"c322ed92-9a7b-4827-b606-d39dc9aef2e8"},"source":["predict"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["851"]},"metadata":{"tags":[]},"execution_count":21}]}]}