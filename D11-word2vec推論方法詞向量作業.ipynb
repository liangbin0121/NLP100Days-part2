{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"cupoy_env","language":"python","name":"cupoy_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"word2vec推論方法詞向量作業.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"sYbea1KZK1Jj"},"source":["### 作業目的: 了解為何需要推論方法的詞向量及其優缺點\n","\n","本次作業主要為思考題，請學員根據題目思考適合的回答"]},{"cell_type":"markdown","metadata":{"id":"pGXDV2cRK1Jq"},"source":["### Q1:\n","請學員思考為何不直接使用one-hot encoding的方式建立詞向量，而要有其他計數方法與推論方法的詞向量產生方式？"]},{"cell_type":"markdown","metadata":{"id":"Vz3Zg73QK1Jq"},"source":["### Answer:\n","##1. 當文本詞彙數量大時，詞向量太過於稀疏(sparse)，造成記憶體資源浪費\n","##2. 詞向量之間為正交關係(orthogonal)，無法充分表達字詞間的相關性"]},{"cell_type":"markdown","metadata":{"id":"WkLqDh7PK1Jr"},"source":["### Q2:\n","相較於計數手法的詞向量(ex: one-hot, 共現矩陣, PPMI)，word2vec的方法有何優點？"]},{"cell_type":"markdown","metadata":{"id":"BMcmjEDiK1Jr"},"source":["### Answer:\n","## 1. 根據分布假說(distribution hypothesis)word2vec會考慮上下文，與計數手法比起來效果較佳\n","## 2. 當新字詞加入時，可以利用先前訓練好的模型當預訓練權重，而不需從頭訓練\n","## 3. 以小批次(mini-batch)進行訓練，因此當文本數量很龐大時，也可以訓練並使用GPU進行運算加速"]},{"cell_type":"code","metadata":{"id":"Jde2JR8BK1Jr"},"source":[""],"execution_count":null,"outputs":[]}]}