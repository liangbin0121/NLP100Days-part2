{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"project_2_3_train_classifier_hw.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Z9PXAejOcIE-"},"source":["### <strong>主題:\n","啤酒評論評分預測 - 分類模型建構\n","### <strong>說明:\n","繼續上次啤酒的評鑑資料集的練習，我們這次的最終目標這要是把啤酒評分的預測當作分類問題 <br />\n","，建構BERT模型，評估其各項屬性(apperance, aroma, overall, palate, taste)得分。特 <br />\n","注意的是，與課程中範例不同的地方在於這次必須預測多個目標，也就是典型的多標籤問題 <br />\n","(multi-label classification)\n","### <strong>題目\n","1. 以上次處理好的啤酒資料為範例，建構相對應的pytorch Dataset與pytorhc Dataloader<br />\n","(完成底下的BeerDataset與create_data_loader)\n","2. 以上次處理好的啤酒資料為範例，建構主要模型的架構(完成底下的BeerRateClassifier)\n","3. 完成最後的訓練流程並得到權重檔，確認模型架構沒有問題\n","\n","#### <strong>提示1: 若同學因GPU限制無法快速訓練，可以考慮調低訓練回合數，MAX_LEN，或選擇較小的bert模型。\n","#### <strong>提示2: 若還是對multi-labeling問題建構不知從何下手，可以考[範例](https://www.learnopencv.com/multi-label-image-classification-with-pytorch/)\n","\n","https://learnopencv.com/multi-label-image-classification-with-pytorch/"]},{"cell_type":"code","metadata":{"id":"ZPLylNv2cJbn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627387607143,"user_tz":-480,"elapsed":388,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"8cccf1a3-c362-4285-84c4-dcd9b034934b"},"source":["# 連接個人資料 讀取 ＰＴＴ 訓練資料和儲存模型\n","#先連接自己的GOOGLE DRIVE 為了要儲存資料和訓練模型\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nIcBMiTQcJeX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627387607402,"user_tz":-480,"elapsed":4,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"870b924f-c4d1-4557-a8ea-d6f35fd7167a"},"source":["import os\n","\n","# Current directory\n","print(os.getcwd())\n","\n","# change directory\n","os.chdir('/content/drive/MyDrive/python_training/NLP100Days-part2/project_2_3/')\n","print(os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/drive/MyDrive/python_training/NLP100Days-part2/project_2_3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xpJH2u8GcJhv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627387615734,"user_tz":-480,"elapsed":8335,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"0e2b00df-c32e-47a7-f93a-5e9223cebf54"},"source":["!pip install torch\n","!pip install transformers\n","#!pip install -q transformers\n","#!pip install transformers==3\n","# 設定 torchtext 版本 安裝完必須重新啟動執行階段\n","!pip install torchtext==0.6.0\n","#!pip install -r requirements.txt\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.9.0+cu102)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (0.1.96)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.5.30)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UuX4r9iGcIFA","executionInfo":{"status":"ok","timestamp":1627387617768,"user_tz":-480,"elapsed":2036,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["import torch\n","import transformers\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn, optim\n","from transformers import BertModel, BertTokenizer\n","from transformers import AdamW, get_linear_schedule_with_warmup"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDbe0EzecIFC","executionInfo":{"status":"ok","timestamp":1627387619912,"user_tz":-480,"elapsed":2145,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["PRE_TRAINED_MODEL_NAME = \"bert-base-cased\"\n","BATCH_SIZE = 16\n","MAX_LEN = 255\n","EPOCHS = 10\n","\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","TOKENIZER = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJXV22jdcIFD","executionInfo":{"status":"ok","timestamp":1627387619912,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["class BeerDataset(Dataset):\n","    \"\"\"\n","    將資料集轉換為後續data DataLoader 需求的 pytorch Dataset形式\n","    Convert beer review dataframe into torch dataset instance\n","    \"\"\"\n","    def __init__(self,\n","                 comments,\n","                 appearance_target,\n","                 aroma_target,\n","                 overall_target,\n","                 palate_target,\n","                 taste_target, max_len):\n","        # 需完成部分...\n","        self.comments = comments\n","        self.appearance_target = appearance_target\n","        self.aroma_target = aroma_target\n","        self.overall_target = overall_target\n","        self.palate_target = palate_target\n","        self.taste_target = taste_target\n","        self.max_len = max_len\n","    def __len__(self):\n","        return len(self.comments)\n","\n","    def __getitem__(self, item):\n","        # 需完成部分...\n","        comment = str(self.comments[item])\n","        appearance_target = self.appearance_target[item]\n","        aroma_target = self.aroma_target[item]\n","        overall_target = self.overall_target[item]\n","        palate_target = self.palate_target[item]\n","        taste_target = self.taste_target[item]\n","        encoding = TOKENIZER.encode_plus(\n","            comment,\n","            max_length=self.max_len,\n","            truncation=True,\n","            add_special_tokens=True,\n","            return_token_type_ids=False,\n","            pad_to_max_length=True,\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )        \n","        return {\n","            'comment': comment,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'appearance_target': torch.tensor(appearance_target, dtype=torch.long),\n","            'aroma_target': torch.tensor(aroma_target, dtype=torch.long),\n","            'overall_target': torch.tensor(overall_target, dtype=torch.long),\n","            'palate_target': torch.tensor(palate_target, dtype=torch.long),\n","            'taste_target': torch.tensor(taste_target, dtype=torch.long)\n","        }"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLnxP65tcIFE","executionInfo":{"status":"ok","timestamp":1627387619913,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def create_data_loader(dataframe, max_len, batch_size):\n","    \"\"\"\n","    將pytorch Dataset形式資料集包裝為data DataLoader\n","    convert dataset to pytorch dataloader format object\n","    \"\"\"\n","    dataset = BeerDataset( # 需完成部分...\n","        comments=dataframe['review/text'],\n","        appearance_target=dataframe.review_appearance,\n","        aroma_target=dataframe.review_aroma,\n","        overall_target=dataframe.review_overall,\n","        palate_target=dataframe.review_palate,\n","        taste_target=dataframe.review_taste,\n","        max_len=max_len)\n","\n","    return DataLoader(\n","        dataset,\n","        batch_size=batch_size\n","    )"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"kQ7hj9OecIFF","executionInfo":{"status":"ok","timestamp":1627387619913,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["class BeerRateClassifier(nn.Module):\n","    \"\"\"\n","    啤酒評論評分分類模型的主體\n","    Beer sentiment main model for review sentiment analyzer\n","    \"\"\"\n","    def __init__(self,\n","                 appearance_n_classes,\n","                 aroma_n_classes,\n","                 overall_n_classes,\n","                 palate_n_classes,\n","                 taste_n_classes,\n","                ):\n","        super(BeerRateClassifier, self).__init__()\n","        # 需完成部分...\n","        aspects = {   \n","            'appearance': appearance_n_classes,\n","            'aroma': aroma_n_classes,\n","            'overall': overall_n_classes,\n","            'palate': palate_n_classes,\n","            'taste': taste_n_classes\n","        }\n","\n","        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","        self.aspect_outs = nn.ModuleDict({\n","            aspect: nn.Linear(self.bert.config.hidden_size, n_classes)\n","            for aspect, n_classes in aspects.items()  \n","        })\n","        self.drop = nn.Dropout(0.2)\n","\n","\n","    def forward(self, input_ids, attention_mask):\n","        # 需完成部分...\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        out = self.drop(outputs.pooler_output) ##outputs['pooler_output']\n","        aspect_outputs = {\n","            aspect: aspect_out(out)\n","            for aspect, aspect_out in self.aspect_outs.items()\n","        }\n","\n","        return aspect_outputs\n","        # return {\n","        #     \"appearance\": appearance_output,\n","        #     \"aroma\": aroma_output,\n","        #     \"overall\": overall_output,\n","        #     \"palate\": palate_output,\n","        #     \"taste\": taste_output,\n","        # }"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwQzVlSFeVQ7","executionInfo":{"status":"ok","timestamp":1627387619913,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def train_epoch(model,\n","                data_loader,\n","                loss_fn,\n","                optimizer,\n","                scheduler,\n","                n_examples):\n","    \"\"\"\n","    分類器的主要訓練流程\n","    Main training process of bert sentiment classifier\n","    \"\"\"\n","    model = model.train()\n","\n","    losses = []\n","    correct_predictions = 0.\n","    for batch in data_loader:\n","        input_ids = batch['input_ids'].to(DEVICE)\n","        attention_mask = batch['attention_mask'].to(DEVICE)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","\n","        preds = {\n","            aspect: torch.max(output, dim=1)[1]\n","            for aspect, output in outputs.items()\n","        }\n","        targets = {\n","            aspect: batch[f\"{aspect}_target\"].view(-1).to(DEVICE)\n","            for aspect in preds.keys()\n","        }\n","        aspect_losses = {\n","            aspect: loss_fn(outputs[aspect], targets[aspect])\n","            for aspect in preds.keys()\n","        }\n","        correct_predictions += sum([\n","            torch.sum(preds[aspect] == targets[aspect]).item() for aspect in preds.keys()\n","        ])\n","\n","        loss = torch.stack([val for _, val in aspect_losses.items()]).sum()\n","        losses.append(loss.item())\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","\n","    return correct_predictions / n_examples / 5, np.mean(losses)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMczLZzOeh5H","executionInfo":{"status":"ok","timestamp":1627387619914,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def eval_model(model,\n","               data_loader,\n","               loss_fn,\n","               n_examples):\n","    \"\"\"\n","    分類器訓練時，每個 epoch 評估流程\n","    Main evaluate process in training of bert sentiment classifier\n","    \"\"\"\n","    model = model.eval()\n","\n","    losses = []\n","    correct_predictions = 0.\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(DEVICE)\n","            attention_mask = batch['attention_mask'].to(DEVICE)\n","            outputs = model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask\n","            )\n","\n","            preds = {\n","                aspect: torch.max(output, dim=1)[1]\n","                for aspect, output in outputs.items()\n","            }\n","            targets = {\n","                aspect: batch[f\"{aspect}_target\"].view(-1).to(DEVICE)\n","                for aspect in preds.keys()\n","            }\n","            aspect_losses = {\n","                aspect: loss_fn(outputs[aspect], targets[aspect])\n","                for aspect in preds.keys()\n","            }\n","            correct_predictions += sum([\n","                torch.sum(preds[aspect] == targets[aspect]).item() for aspect in preds.keys()\n","            ])\n","\n","            loss = torch.stack([val for _, val in aspect_losses.items()]).sum()\n","            losses.append(loss.item())\n","\n","    return correct_predictions / n_examples / 5, np.mean(losses)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ONkGJ4NcIFH","executionInfo":{"status":"ok","timestamp":1627387621234,"user_tz":-480,"elapsed":1325,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["TRAIN = pd.read_json(\"./data/train_set_lng.json\")\n","TRAIN = TRAIN.sample(frac=1).reset_index(drop=True)\n","VAL = pd.read_json(\"./data/test_set_lng.json\")\n","VAL = VAL.sample(frac=1).reset_index(drop=True)\n","TRAIN = TRAIN.append(VAL[500:]).reset_index(drop=True)\n","VAL = VAL.iloc[:500]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"vFvS-blv1fpq","executionInfo":{"status":"ok","timestamp":1627387621235,"user_tz":-480,"elapsed":8,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"b515e081-fb28-4bf5-c10b-1dcce3f90aee"},"source":["TRAIN.head(2)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>beer/ABV</th>\n","      <th>beer/beerId</th>\n","      <th>beer/brewerId</th>\n","      <th>beer/name</th>\n","      <th>beer/style</th>\n","      <th>review/appearance</th>\n","      <th>review/aroma</th>\n","      <th>review/overall</th>\n","      <th>review/palate</th>\n","      <th>review/taste</th>\n","      <th>review/text</th>\n","      <th>review/timeStruct</th>\n","      <th>review/timeUnix</th>\n","      <th>user/ageInSeconds</th>\n","      <th>user/birthdayRaw</th>\n","      <th>user/birthdayUnix</th>\n","      <th>user/gender</th>\n","      <th>user/profileName</th>\n","      <th>review_appearance</th>\n","      <th>review_aroma</th>\n","      <th>review_overall</th>\n","      <th>review_palate</th>\n","      <th>review_taste</th>\n","      <th>text_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39708</td>\n","      <td>5.11</td>\n","      <td>28950</td>\n","      <td>13397</td>\n","      <td>Nut Brown Ale</td>\n","      <td>English Brown Ale</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.0</td>\n","      <td>12oz brown bottle serveed into a nonic glass.\\...</td>\n","      <td>{'min': 6, 'hour': 2, 'mday': 12, 'sec': 24, '...</td>\n","      <td>1213236384</td>\n","      <td>1.677420e+09</td>\n","      <td>Oct 16, 1961</td>\n","      <td>-259084800.0</td>\n","      <td>Male</td>\n","      <td>jcdiflorio</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>8266</td>\n","      <td>8.50</td>\n","      <td>29687</td>\n","      <td>395</td>\n","      <td>Jefferson's Reserve Bourbon Barrel Stout</td>\n","      <td>American Double / Imperial Stout</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Picked this up in Ohio along with the other be...</td>\n","      <td>{'min': 29, 'hour': 6, 'mday': 11, 'sec': 34, ...</td>\n","      <td>1231655374</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>JerzDevl2000</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>211</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index  beer/ABV  beer/beerId  ...  review_palate review_taste text_length\n","0  39708      5.11        28950  ...              1            1          90\n","1   8266      8.50        29687  ...              3            3         211\n","\n","[2 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"I1EmofOS1fsZ","executionInfo":{"status":"ok","timestamp":1627387621235,"user_tz":-480,"elapsed":5,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"ed359f91-2d45-4a30-ab53-15cc512947d7"},"source":["VAL.head(2)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>beer/ABV</th>\n","      <th>beer/beerId</th>\n","      <th>beer/brewerId</th>\n","      <th>beer/name</th>\n","      <th>beer/style</th>\n","      <th>review/appearance</th>\n","      <th>review/aroma</th>\n","      <th>review/overall</th>\n","      <th>review/palate</th>\n","      <th>review/taste</th>\n","      <th>review/text</th>\n","      <th>review/timeStruct</th>\n","      <th>review/timeUnix</th>\n","      <th>user/ageInSeconds</th>\n","      <th>user/birthdayRaw</th>\n","      <th>user/birthdayUnix</th>\n","      <th>user/gender</th>\n","      <th>user/profileName</th>\n","      <th>review_appearance</th>\n","      <th>review_aroma</th>\n","      <th>review_overall</th>\n","      <th>review_palate</th>\n","      <th>review_taste</th>\n","      <th>text_length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24760</td>\n","      <td>6.9</td>\n","      <td>23474</td>\n","      <td>1199</td>\n","      <td>Founders RÃ¼bÃ¦us</td>\n","      <td>Fruit / Vegetable Beer</td>\n","      <td>3.5</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>4.0</td>\n","      <td>Pours from the bottle a reddish copper hue wit...</td>\n","      <td>{'min': 47, 'hour': 23, 'mday': 29, 'sec': 16,...</td>\n","      <td>1154216836</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Male</td>\n","      <td>merlin48</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>42257</td>\n","      <td>8.0</td>\n","      <td>54731</td>\n","      <td>263</td>\n","      <td>Aecht Schlenkerla Eiche</td>\n","      <td>Doppelbock</td>\n","      <td>3.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>4.0</td>\n","      <td>4.5</td>\n","      <td>500ml bottle.\\t\\tPours a slightly hazy orangy ...</td>\n","      <td>{'min': 3, 'hour': 1, 'mday': 9, 'sec': 28, 'y...</td>\n","      <td>1320800608</td>\n","      <td>NaN</td>\n","      <td>None</td>\n","      <td>NaN</td>\n","      <td>Male</td>\n","      <td>rangerred</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>88</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index  beer/ABV  beer/beerId  ...  review_palate review_taste text_length\n","0  24760       6.9        23474  ...              2            2          87\n","1  42257       8.0        54731  ...              2            3          88\n","\n","[2 rows x 25 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"1KTa4x1EcIFJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627387626789,"user_tz":-480,"elapsed":5559,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"bf999d19-c021-4a1f-d63a-4f1cfe518754"},"source":["MODEL = BeerRateClassifier(4, 4, 4, 4, 4)\n","MODEL.to(DEVICE)\n","\n","TRAIN_DATA_LOADER = create_data_loader(TRAIN, MAX_LEN, BATCH_SIZE)\n","VAL_DATA_LOADER = create_data_loader(VAL, MAX_LEN, BATCH_SIZE)\n","\n","OPTIMIZER = AdamW(MODEL.parameters(), lr=2e-5, correct_bias=False)\n","TOTAL_STEPS = len(TRAIN_DATA_LOADER) * EPOCHS\n","SCHEDULER = get_linear_schedule_with_warmup(\n","    OPTIMIZER,\n","    num_warmup_steps=0,\n","    num_training_steps=TOTAL_STEPS\n",")\n","LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tqRP28vQcIFK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be422f84-d2b2-4062-dcc8-3641f68d02a4"},"source":["BEST_ACCURACY = 0\n","\n","for epoch in range(EPOCHS):\n","    print(f'Epoch {epoch + 1}/{EPOCHS}')\n","    print('-' * 10)\n","\n","    train_acc, train_loss = train_epoch(\n","        MODEL,\n","        TRAIN_DATA_LOADER,\n","        LOSS_FN,\n","        OPTIMIZER,\n","        SCHEDULER,\n","        len(TRAIN)\n","    )\n","\n","    print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","    val_acc, val_loss = eval_model(\n","        MODEL,\n","        VAL_DATA_LOADER,\n","        LOSS_FN,\n","        len(VAL)\n","    )\n","\n","    print(f'Val   loss {val_loss} accuracy {val_acc}')\n","    print()\n","\n","    if val_acc > BEST_ACCURACY:\n","        MODEL.bert.save_pretrained(\"./\")\n","        best_accuracy = val_acc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Train loss 4.704062187525251 accuracy 0.5284323232323233\n","Val   loss 4.423305444419384 accuracy 0.5599999999999999\n","\n","Epoch 2/10\n","----------\n","Train loss 4.357919468368032 accuracy 0.5706141414141415\n","Val   loss 4.44634410738945 accuracy 0.5556\n","\n","Epoch 3/10\n","----------\n","Train loss 4.076980198285005 accuracy 0.6081414141414141\n","Val   loss 4.592077486217022 accuracy 0.5396\n","\n","Epoch 4/10\n","----------\n"],"name":"stdout"}]}]}