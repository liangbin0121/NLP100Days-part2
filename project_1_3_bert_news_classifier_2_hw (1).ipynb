{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project_1_3_bert_news_classifier_2_hw.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"18MpM6ztu2jT"},"source":["# 專題（二）：訓練 Bert 新聞分類器並提升精準度\n","\n","## 專案目標\n","- 目標：請試著建製 BertForSequenceClassification 看得懂的資料集 NewsDataset\n","- news_clustering_train.tsv 中有 1800 篇新聞，六種類別的新聞各 300 篇\n","- news_clustering_test.tsv 中有 600 篇新聞，六種類別的新聞各 100 篇\n","- 六種類別：體育、財經、科技、旅遊、農業、遊戲\n","\n","## 實作提示\n","- STEP1 - STEP4：資料處理\n","- STEP5：創造 train_batch 函數\n","- STEP6：創造 evaluate 函數\n","- STEP7：組合以上元素開始訓練，如果正確 validation accuracy 應該可以超過 90% 以上\n","\n","## 重要知識點：專題結束後你可以學會\n","- 了解 BERT 的 Sequence Classification 任務如何進行\n","- 使用 TRAIN / VALID DATA 來了解深度學習模型的訓練情形\n","- 了解預訓練模型在 NLP 上的威力"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_QD7nqgv5VS","executionInfo":{"status":"ok","timestamp":1626735155293,"user_tz":-480,"elapsed":417,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"355fd715-2ea1-4647-ee39-7fcf920489a6"},"source":["# 連接個人資料 讀取 ＰＴＴ 訓練資料和儲存模型\n","#先連接自己的GOOGLE DRIVE 為了要儲存資料和訓練模型\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgV-YCkNv5SD","executionInfo":{"status":"ok","timestamp":1626735155699,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"123b891b-3d00-467e-b3cc-436217aed8d1"},"source":["import os\n","\n","# Current directory\n","print(os.getcwd())\n","\n","# change directory\n","os.chdir('/content/drive/MyDrive/python_training/NLP100Days-part2/project_1_3/')\n","print(os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content\n","/content/drive/MyDrive/python_training/NLP100Days-part2/project_1_3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2GDmjOyYMklS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626735155700,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"23853c2b-5fd5-467a-876e-d9d7673b7169"},"source":["!python --version"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Python 3.7.11\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1JkVfTP5Qn-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626735163309,"user_tz":-480,"elapsed":7612,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"cb613eb6-f70f-4e42-a73a-3725f6fb8502"},"source":["!pip install torch\n","!pip install transformers\n","#!pip install -q transformers\n","# 設定 torchtext 版本 安裝完必須重新啟動執行階段\n","!pip install torchtext==0.6.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (0.1.96)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.9.0+cu102)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WKW9s5YtMvop","executionInfo":{"status":"ok","timestamp":1626735163723,"user_tz":-480,"elapsed":423,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from transformers import BertTokenizer, BertForSequenceClassification"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8OlmfVQM7UW","executionInfo":{"status":"ok","timestamp":1626735163724,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["df_train = pd.read_csv('news_clustering_train.tsv', sep='\\t')\n","df_test = pd.read_csv('news_clustering_test.tsv', sep='\\t')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivoJVDvnM_Ok","executionInfo":{"status":"ok","timestamp":1626735164284,"user_tz":-480,"elapsed":562,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["train_titles = {row['index']: row['title'] for _, row in df_train.iterrows()}\n","train_classes = {row['index']: row['class'] for _, row in df_train.iterrows()}\n","\n","valid_titles = {row['index']: row['title'] for _, row in df_test.iterrows()}\n","valid_classes = {row['index']: row['class'] for _, row in df_test.iterrows()}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"QM8vITkwNMJP","executionInfo":{"status":"ok","timestamp":1626735164284,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["ALL_NEWS_CLASSES = ['體育', '財經', '科技', '旅遊', '農業', '遊戲']"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACnCRl2xNV3r","executionInfo":{"status":"ok","timestamp":1626735164284,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["MODEL_NAME = 'bert-base-chinese'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"rK1yhgITcL3Q","executionInfo":{"status":"ok","timestamp":1626735164285,"user_tz":-480,"elapsed":3,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["# 建立數據集\n","class NewsDataset(Dataset):\n","    def __init__(self, tokenizer, titles, classes):\n","        self.tokenizer = tokenizer\n","        self.indexes = []\n","        self.texts = []\n","        self.labels = []\n","        for index in titles:\n","            self.indexes.append(index)\n","            self.texts.append(titles[index])\n","            self.labels.append(classes[index])\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","\n","        input = self.tokenizer(text, return_tensors='pt')\n","        label = torch.tensor(ALL_NEWS_CLASSES.index(self.labels[idx]))\n","\n","        return input, label\n","\n","    def __len__(self):\n","        return len(self.indexes)\n","\n","\n","def create_mini_batch(samples):\n","    input_ids = []\n","    token_type_ids = []\n","    attention_mask = []\n","    labels = []\n","    for s in samples:\n","        input_ids.append(s[0]['input_ids'].squeeze(0))\n","        token_type_ids.append(s[0]['token_type_ids'].squeeze(0))\n","        attention_mask.append(s[0]['attention_mask'].squeeze(0))\n","        labels.append(s[1])\n","\n","    # zero pad 到同一序列長度\n","    input_ids = pad_sequence(input_ids, batch_first=True)\n","    token_type_ids = pad_sequence(token_type_ids, batch_first=True)\n","    attention_mask = pad_sequence(attention_mask, batch_first=True)\n"," \n","    labels = torch.stack(labels)\n","\n","    return input_ids, token_type_ids, attention_mask, labels"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"4cmG8VcfeiNN","executionInfo":{"status":"ok","timestamp":1626735165865,"user_tz":-480,"elapsed":1583,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["batch_size = 32\n","\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n","\n","train_dataset = NewsDataset(tokenizer, train_titles, train_classes)\n","valid_dataset = NewsDataset(tokenizer, valid_titles, valid_classes)\n","\n","train_loader = DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    collate_fn=create_mini_batch,\n","    shuffle=True)\n","valid_loader = DataLoader(\n","    dataset=valid_dataset,\n","    batch_size=batch_size,\n","    collate_fn=create_mini_batch)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4dwpy9GQlY2","executionInfo":{"status":"ok","timestamp":1626735165870,"user_tz":-480,"elapsed":7,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def train_batch(model, data, optimizer, device):\n","    model.train()\n","    input_ids, token_type_ids, attention_mask, labels = [d.to(device) for d in data]\n","\n","    # Code Here\n","    outputs = model(\n","        input_ids=input_ids,\n","        token_type_ids=token_type_ids,\n","        attention_mask=attention_mask,\n","        labels=labels\n","    )\n","    loss = outputs.loss\n","    # End\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nFmo31hZoLQ","executionInfo":{"status":"ok","timestamp":1626735165870,"user_tz":-480,"elapsed":6,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":["def evaluate(model, valid_loader):\n","    model.eval()\n","    device = 'cuda' if next(model.parameters()).is_cuda else 'cpu'\n","\n","    tot_count = 0\n","    tot_loss = 0\n","    tot_correct = 0\n","\n","    with torch.no_grad():\n","        for data in valid_loader:\n","            input_ids, token_type_ids, attention_mask, labels = [d.to(device) for d in data]\n","\n","            # Code Here\n","            outputs = model(\n","                input_ids=input_ids,\n","                token_type_ids=token_type_ids,\n","                attention_mask=attention_mask,\n","                labels=labels\n","            )\n","            \n","            tot_count += input_ids.size(0)\n","            tot_loss += outputs.loss.item()\n","            tot_correct += (outputs.logits.argmax(dim=-1) == labels).sum().item()\n","            \n","            # End\n","    \n","    evaluation = {\n","        'loss': tot_loss / tot_count,\n","        'acc': tot_correct / tot_count\n","    }\n","    return evaluation"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"mg-X2pRHQ2bx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626735247154,"user_tz":-480,"elapsed":81290,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"8592f49f-5be0-4112-d1d6-9ca351f66aba"},"source":["# 訓練模型\n","epochs = 5\n","lr = 0.0001\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = BertForSequenceClassification.from_pretrained( # Code Here\n","    MODEL_NAME, \n","    num_labels=6, \n","    return_dict=True\n",")\n","\n","model.to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","\n","for epoch in range(1, epochs + 1):\n","    print(f'epoch: {epoch}')\n","\n","    for i, train_data in enumerate(train_loader):\n","        loss = train_batch(model, train_data, optimizer, device)\n","        train_size = train_data[0].size(0)\n","\n","        if i % 10 == 0:\n","            print('train_loss: ', loss / train_size)\n","\n","    evaluation = evaluate(model, valid_loader)\n","    print('valid_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n","\n","    scheduler.step()    "],"execution_count":14,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 1\n","train_loss:  0.060375235974788666\n","train_loss:  0.028474539518356323\n","train_loss:  0.014009310863912106\n","train_loss:  0.01560203731060028\n","train_loss:  0.018747208639979362\n","train_loss:  0.007590021472424269\n","valid_evaluation: loss=0.013293009257564941, acc=0.8916666666666667\n","epoch: 2\n","train_loss:  0.0150650255382061\n","train_loss:  0.007151269353926182\n","train_loss:  0.02121441625058651\n","train_loss:  0.01409535575658083\n","train_loss:  0.001541155157610774\n","train_loss:  0.014083714224398136\n","valid_evaluation: loss=0.014841606517632803, acc=0.8716666666666667\n","epoch: 3\n","train_loss:  0.0036476710811257362\n","train_loss:  0.005735544487833977\n","train_loss:  0.008524185977876186\n","train_loss:  0.002162025310099125\n","train_loss:  0.00396896293386817\n","train_loss:  0.0009688572026789188\n","valid_evaluation: loss=0.010937012293531249, acc=0.9016666666666666\n","epoch: 4\n","train_loss:  0.00845180731266737\n","train_loss:  0.0029194143135100603\n","train_loss:  0.0018559604650363326\n","train_loss:  0.005174604244530201\n","train_loss:  0.0031367072369903326\n","train_loss:  0.003914725501090288\n","valid_evaluation: loss=0.011648640827431033, acc=0.9\n","epoch: 5\n","train_loss:  0.0013603034894913435\n","train_loss:  0.0043960753828287125\n","train_loss:  0.0008588946075178683\n","train_loss:  0.0013491909485310316\n","train_loss:  0.0016467359382659197\n","train_loss:  0.00086244783597067\n","valid_evaluation: loss=0.011538949767903735, acc=0.9016666666666666\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPq2lkZQ-rRz","executionInfo":{"status":"ok","timestamp":1626735302779,"user_tz":-480,"elapsed":250,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}},"outputId":"e2f99dc9-8590-43b1-e899-d34ff151853f"},"source":["evaluation"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'acc': 0.9016666666666666, 'loss': 0.011538949767903735}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"8pqBzK-69zB_"},"source":["train_loss:  0.002987815300002694\n","\n","valid_evaluation: loss=0.010043316627852619, acc=0.9133333333333333"]},{"cell_type":"code","metadata":{"id":"O1gYsYaSlk1c","executionInfo":{"status":"ok","timestamp":1626735247155,"user_tz":-480,"elapsed":13,"user":{"displayName":"蔡良彬","photoUrl":"","userId":"04145839673132622291"}}},"source":[""],"execution_count":14,"outputs":[]}]}